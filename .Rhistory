geom_linerange(
aes(x=seq(1,num_samples),
ymin = CI[,1],
ymax = CI[,2],
col=is_mu_in_CI
)
)+
scale_color_manual(values=c("TRUE"="blue","FALSE"="red"))+
guides(col=FALSE)+
labs(title="Confidence Intervals", x="Sample Number")+
geom_hline(yintercept=pop_mean, col="red")+
coord_cartesian(ylim = c(pop_mean-pop_sd, pop_mean+pop_sd))
# How many of the confidence intervals capture the population mean?
mean(is_mu_in_CI)
# This makes sure we get the same random numbers every time
set.seed(123)
# Setting the parameters of the simulation
sample_size <- 100
num_samples <- 50
ci_level <-0.95
# theoretical pop mean / standard deviation (sd) For std. norm. it is 0,1. Changes other normal.
pop_mean<-0
pop_sd<-1
# drawing randomly from the distribution and forming it into a matrix
# each row of the matrix is a sample, each column is an observation of the sample
# matrix dimension is num_samples (row) by sample_size (column)
# this uses the normal distribution
r_draws <- matrix(rnorm(sample_size*num_samples, pop_mean, pop_sd),num_samples,sample_size)
# Constructing the sample mean as the row mean
# help(apply) describes what it does
sample_mean <- apply(r_draws,1,mean)
# finding the margin of error
moe <- qnorm(1-(1-ci_level)/2)*pop_sd/sqrt(sample_size)
# binding x\bar-moe and x\bar+moe as two columns
CI <- cbind(sample_mean-moe,sample_mean+moe)
# the proportion of CI that have population mean within the CI
mean( (pop_mean>CI[,1]) & (pop_mean<CI[,2]))
# to make the nice picture, you need the user written package ggplot2
## you might need to type: install.packages("ggplot2") into the console if you get an error
require(ggplot2)
# a logical vector, TRUE if the confidence intercal captures the population mean
is_mu_in_CI <- ((pop_mean>CI[,1]) & (pop_mean<CI[,2]))
## making the plot
ggplot()+
geom_linerange(
aes(x=seq(1,num_samples),
ymin = CI[,1],
ymax = CI[,2],
col=is_mu_in_CI
)
)+
scale_color_manual(values=c("TRUE"="blue","FALSE"="red"))+
guides(col=FALSE)+
labs(title="Confidence Intervals", x="Sample Number")+
geom_hline(yintercept=pop_mean, col="red")+
coord_cartesian(ylim = c(pop_mean-pop_sd, pop_mean+pop_sd))
# How many of the confidence intervals capture the population mean?
mean(is_mu_in_CI)
# This makes sure we get the same random numbers every time
set.seed(123)
# Setting the parameters of the simulation
sample_size <- 100
num_samples <- 100
ci_level <-0.95
# theoretical pop mean / standard deviation (sd) For std. norm. it is 0,1. Changes other normal.
pop_mean<-0
pop_sd<-1
# drawing randomly from the distribution and forming it into a matrix
# each row of the matrix is a sample, each column is an observation of the sample
# matrix dimension is num_samples (row) by sample_size (column)
# this uses the normal distribution
r_draws <- matrix(rnorm(sample_size*num_samples, pop_mean, pop_sd),num_samples,sample_size)
# Constructing the sample mean as the row mean
# help(apply) describes what it does
sample_mean <- apply(r_draws,1,mean)
# finding the margin of error
moe <- qnorm(1-(1-ci_level)/2)*pop_sd/sqrt(sample_size)
# binding x\bar-moe and x\bar+moe as two columns
CI <- cbind(sample_mean-moe,sample_mean+moe)
# the proportion of CI that have population mean within the CI
mean( (pop_mean>CI[,1]) & (pop_mean<CI[,2]))
# to make the nice picture, you need the user written package ggplot2
## you might need to type: install.packages("ggplot2") into the console if you get an error
require(ggplot2)
# a logical vector, TRUE if the confidence intercal captures the population mean
is_mu_in_CI <- ((pop_mean>CI[,1]) & (pop_mean<CI[,2]))
## making the plot
ggplot()+
geom_linerange(
aes(x=seq(1,num_samples),
ymin = CI[,1],
ymax = CI[,2],
col=is_mu_in_CI
)
)+
scale_color_manual(values=c("TRUE"="blue","FALSE"="red"))+
guides(col=FALSE)+
labs(title="Confidence Intervals", x="Sample Number")+
geom_hline(yintercept=pop_mean, col="red")+
coord_cartesian(ylim = c(pop_mean-pop_sd, pop_mean+pop_sd))
# How many of the confidence intervals capture the population mean?
mean(is_mu_in_CI)
# This makes sure we get the same random numbers every time
set.seed(123)
# Setting the parameters of the simulation
sample_size <- 100
num_samples <- 50
ci_level <-0.8
# theoretical pop mean / standard deviation (sd) For std. norm. it is 0,1. Changes other normal.
pop_mean<-0
pop_sd<-1
# drawing randomly from the distribution and forming it into a matrix
# each row of the matrix is a sample, each column is an observation of the sample
# matrix dimension is num_samples (row) by sample_size (column)
# this uses the normal distribution
r_draws <- matrix(rnorm(sample_size*num_samples, pop_mean, pop_sd),num_samples,sample_size)
# Constructing the sample mean as the row mean
# help(apply) describes what it does
sample_mean <- apply(r_draws,1,mean)
# finding the margin of error
moe <- qnorm(1-(1-ci_level)/2)*pop_sd/sqrt(sample_size)
# binding x\bar-moe and x\bar+moe as two columns
CI <- cbind(sample_mean-moe,sample_mean+moe)
# the proportion of CI that have population mean within the CI
mean( (pop_mean>CI[,1]) & (pop_mean<CI[,2]))
# to make the nice picture, you need the user written package ggplot2
## you might need to type: install.packages("ggplot2") into the console if you get an error
require(ggplot2)
# a logical vector, TRUE if the confidence intercal captures the population mean
is_mu_in_CI <- ((pop_mean>CI[,1]) & (pop_mean<CI[,2]))
## making the plot
ggplot()+
geom_linerange(
aes(x=seq(1,num_samples),
ymin = CI[,1],
ymax = CI[,2],
col=is_mu_in_CI
)
)+
scale_color_manual(values=c("TRUE"="blue","FALSE"="red"))+
guides(col=FALSE)+
labs(title="Confidence Intervals", x="Sample Number")+
geom_hline(yintercept=pop_mean, col="red")+
coord_cartesian(ylim = c(pop_mean-pop_sd, pop_mean+pop_sd))
# How many of the confidence intervals capture the population mean?
mean(is_mu_in_CI)
# This makes sure we get the same random numbers every time
set.seed(123)
# Setting the parameters of the simulation
sample_size <- 100
num_samples <- 50
ci_level <-0.9
# theoretical pop mean / standard deviation (sd) For std. norm. it is 0,1. Changes other normal.
pop_mean<-0
pop_sd<-1
# drawing randomly from the distribution and forming it into a matrix
# each row of the matrix is a sample, each column is an observation of the sample
# matrix dimension is num_samples (row) by sample_size (column)
# this uses the normal distribution
r_draws <- matrix(rnorm(sample_size*num_samples, pop_mean, pop_sd),num_samples,sample_size)
# Constructing the sample mean as the row mean
# help(apply) describes what it does
sample_mean <- apply(r_draws,1,mean)
# finding the margin of error
moe <- qnorm(1-(1-ci_level)/2)*pop_sd/sqrt(sample_size)
# binding x\bar-moe and x\bar+moe as two columns
CI <- cbind(sample_mean-moe,sample_mean+moe)
# the proportion of CI that have population mean within the CI
mean( (pop_mean>CI[,1]) & (pop_mean<CI[,2]))
# to make the nice picture, you need the user written package ggplot2
## you might need to type: install.packages("ggplot2") into the console if you get an error
require(ggplot2)
# a logical vector, TRUE if the confidence intercal captures the population mean
is_mu_in_CI <- ((pop_mean>CI[,1]) & (pop_mean<CI[,2]))
## making the plot
ggplot()+
geom_linerange(
aes(x=seq(1,num_samples),
ymin = CI[,1],
ymax = CI[,2],
col=is_mu_in_CI
)
)+
scale_color_manual(values=c("TRUE"="blue","FALSE"="red"))+
guides(col=FALSE)+
labs(title="Confidence Intervals", x="Sample Number")+
geom_hline(yintercept=pop_mean, col="red")+
coord_cartesian(ylim = c(pop_mean-pop_sd, pop_mean+pop_sd))
# How many of the confidence intervals capture the population mean?
mean(is_mu_in_CI)
bus_stop_time = read.csv('https://mattbutner.github.io/data/bus_stop_time.csv')
hist(bus_stop_time$time_until_bus, main="Histogram of Bus Stop Time", xlab = "Time Until Bus (Minutes)", breaks = 10)
mean (bus_stop_time$time_until_bus)
sd(bus_stop_time$time_until_bus)
length(bus_stop_time$time_until_bus)
mean(bus_stop_time$time_until_bus) + c(-1,1) * qnorm(0.95) * (sd(bus_stop_time$time_until_bus) / sqrt(length(bus_stop_time$time_until_bus)))
mean(bus_stop_time$time_until_bus) + c(-1,1) * qnorm(0.975) * (sd(bus_stop_time$time_until_bus) / sqrt(length(bus_stop_time$time_until_bus)))
mean(bus_stop_time$time_until_bus) + c(-1,1) * qnorm(0.975) * (sd(bus_stop_time$time_until_bus) / sqrt(length(bus_stop_time$time_until_bus)))
library(readxl)
ex07_005a <- read_excel("Downloads/ex07-005a.xlsx")
View(ex07_005a)
sd(ex07_005a$Size..cm.3.)
mean(ex07_005a$Size..cm.3.)
library(readxl)
ex20_51RTLFT <- read_excel("Downloads/ex20-51RTLFT.xls")
View(ex20_51RTLFT)
x = ex20_51RTLFT$Right - ex20_51RTLFT$Left
x
x = x * -1
x
mean(x)
sd(x)
`^GSPC` <- read.csv("~/Downloads/^GSPC.csv")
View(`^GSPC`)
^GSPC
View(`^GSPC`)
View(`^GSPC`)
sd(^GSPC$Open)
sd("^GSPC$Open")
View(`^GSPC`)
sp <- read.csv("~/Downloads/sp.csv")
View(sp)
sp$DailyGain = ((sp$Close - sp$Open) / sp$Open)
sp$DailyGain = 1
sp$DailyGain = (sp$Open - sp$Open[-0]) / sp$Open
sp$DailyGain = ((sp$Open - sp$Open[-0]) / sp$Open)
sp$DailyGain = ((sp$Open - sp$Open) / sp$Open)
sp$DailyGain = ((sp$Open - sp$Open[-1]) / sp$Open)
sp$DailyGain = ((sp$Open[-1] - sp$Open) / sp$Open)
sp$DailyGain = ((sp$Open[-1] - sp$Open)
a
sp$DailyGain = ((sp$Open[-1] - sp$Open))
sp$DailyGain = ((sp$Open[-1] - sp$Open) / sp$Open)
sp$DailyGain = ((sp$Open[-1] - sp$Open) / sp$Open)
sp$DailyGain = 1 + ((sp$Open[-1] - sp$Open) / sp$Open)
ex04.30losses <- read.csv("~/Downloads/ex04-30losses.csv")
View(ex04.30losses)
cor()
cor(ex04.30losses$Behave, ex04.30losses$Neural)
cor( ex04.30losses$Neural, ex04.30losses$Behave)
ex04.30losses$Neural
ex04.30losses$Neural[0:15]
cor(ex04.30losses$Behave[0:15], ex04.30losses$Neural[0:15])
cor(ex04.30losses$Behave[0:15], ex04.30losses$Neural[0:15], method="pearson")
ex04.31lifeexp <- read.csv("~/Downloads/ex04-31lifeexp.csv", header=FALSE)
View(ex04.31lifeexp)
ex04.31lifeexp$V1[0:]
ex04.31lifeexp$V1[1:21]
ex04.31lifeexp$V1[2:21]
help(qnorm)
qnorm(1.96)
qnorm(0.5)
qnorm(0.75)
qnorm(025)
qnorm(0.25)
qnorm(0.95)
xbar = 955
sigma = 200
n = 50
h0 = 1000
sstat = (xbar - h0) / (sigma / sqrt(n))
sstat
qnorm(0.05)
pnorm(sstat)
pnorm(1.645)
pnorm(sstat)
help(seq)
seq(10, 15)
seq(10, 15, 5)
seq(10, 200, 5)
n = seq(10, 200, 5)
p = pnorm(n)
p
p = pnorm((xbar - h0) / (sigma / sqrt(n)))
p
n = seq(10, 200, 5)
pvals = pnorm((xbar - h0) / (sigma / sqrt(n)))
histogram(pvals)
hist(pvals)
help(plot)
plot(n, pvals, xlab="Sample size", ylab="P-Value")
help(plot)
plot(n, pvals, xlab="Sample size", ylab="P-Value", type="b")
plot(n, pvals, xlab="Sample size", ylab="P-Value")
help(plot)
plot(n, pvals, xlab="Sample size", ylab="P-Value")
pvals
n
pnorm((xbar - h0) / (sigma / sqrt(135)))
pnorm((xbar - h0) / (sigma / sqrt(130)))
pnorm((xbar - h0) / (sigma / sqrt(55)))
pnorm((xbar - h0) / (sigma / sqrt(50)))
xbar
h0
sigma
sigma = 220
sstat = (xbar - h0) / (sigma / sqrt(n))
sstat
sstat
n = 50
sstat = (xbar - h0) / (sigma / sqrt(n))
sstat
xbar
n
sigma
h0
sstat = (xbar - h0) / (sigma / sqrt(n))
sstat
pnorm(sstat)
n = seq(10, 200, 5)
n
pvals = pnorm((xbar - h0) / (sigma / sqrt(n)))
plot(n, pvals, xlab="Sample size", ylab="P-Value")
pvals
n
pvals = pnorm((xbar - h0) / (sigma / sqrt(65)))
pvals
pnorm((xbar - h0) / (sigma / sqrt(60)))
qnorm(0.05)
pnorm(-1.644854)
(qnorm(0.05) / ((xbar - h0) / sigma))^2
pnorm(64.66583)
pnorm((xbar - h0) / (sigma / sqrt(64.66583)))
pnorm((xbar - h0) / (sigma / sqrt(64.66584)))
xbar = seq(920, 1000, 5)
xbar
n = 50
pvals = pnorm((xbar - h0) / (sigma / sqrt(n)))
plot(xbar, pvals, xlab="Sample Average", ylab="P-Value")
pvals
xbar
pvals
xbar
pvals < 0.05
n
xbar
sigma
h0
qnorm(0.05)
((qnorm(0.05) / sqrt(n))(sigma)) - h0
((qnorm(0.05) / sqrt(n))*(sigma)) - h0
((qnorm(0.05) / sqrt(n))*(sigma)) + h0
pnorm((948.8242 - h0) / (sigma/sqrt(n)))
xbar = 955
sigma = seq(120, 250, 5)
sigma
pvals = pnorm((xbar - h0) / (sigma / sqrt(n)))
xbar
h0
sigma
n
plot(sigma, pvals, xlab="Population Standard Deviation", ylab="P-Value")
pvals
pvals < 0.05
sigma
pnorm((xbar - h0) / (190 / sqrt(n)))
pnorm((xbar - h0) / (195 / sqrt(n)))
(xbar - h0) / (qnorm(0.05) / sqrt(n))
pnorm((xbar - h0) / (193.4507  / sqrt(n)))
sigma = 220
xbar
n
h0
tru_mu = seq(800, 1000, 10)
((qnorm(0.05) / sqrt(n))*(sigma)) + h0
pnorm((948.8242 - h0) / (sigma / sqrt(n)))
pnorm((947.8242 - h0) / (sigma / sqrt(n)))
true_mu = seq(800, 1000, 10)
((qnorm(0.05) / sqrt(n))*(sigma)) + true_my
((qnorm(0.05) / sqrt(n))*(sigma)) + true_mu
pnorm(1)
xrej = ((qnorm(0.05) / sqrt(n))*(sigma)) + h0
xrej
pnorm((xrej - true_my) / (sigma / sqrt(n)))
pnorm((xrej - true_mu) / (sigma / sqrt(n)))
p_altmu = pnorm((xrej - true_mu) / (sigma / sqrt(n)))
xrej
true_my
true_mu
sigma
xrej
true_my
true_mu
p_altmu = pnorm((xrej - true_mu) / (sigma / sqrt(n)))
p_altmu
xrej - 800
(xrej - 800) / (220 / sqrt(50))
220 / sqrt(50)
xrej - 1000
(xrej - 1000 ) / 31.11
plot(true_mu, p_altmu, xlab="True mean", ylab="Power")
p_altmu
true_mu
pnorm((xrej - 920) / (sigma / sqrt(n)))
pnorm((xrej - 925) / (sigma / sqrt(n)))
qnorm(0.8)
xrej - ((qnorm(0.8) / sqrt(n)) * sigma)
pnorm((xrej - 922.6391) / (sigma / sqrt(n)))
load
load(https://mattbutner.github.io/data/bus_stop_time.csv)
load("https://mattbutner.github.io/data/bus_stop_time.csv"")
asdf
asdf
asdf
asdf
asdf
asdf
asdf
asdf
bus = load ("https://mattbutner.github.io/data/bus_stop_time.csv")
bus_stop_time = read.csv('https://mattbutner.github.io/data/bus_stop_time.csv')
t.test
help(t.test)
View(bus_stop_time)
View(bus_stop_time)
t.test(bus_stop_time$time_until_bus, mu = 5)
source('~/Documents/ECON/RProj.R')
# Import stock data
sp_data = read.csv('SP.csv')
emerging_data = read.csv('EEM.csv')
# Split data into quarters of the year
library(lubricate)
sp_quarters = split(sp_data, quarter(sp_data$Date, with_year=TRUE))
emerging_quarters = split(emerging_data, quarter(emerging_data$Date, with_year=TRUE))
# Analyze the coefficient of variation
calculate_cv = function(vec) {
return (sd(vec$Adj.Close) / mean(vec$Adj.Close))
}
# Calculate cv for each quarter and combine into a single dataframe
sp_cv = lapply(sp_quarters, calculate_cv)
sp_cv = data.frame(
Quarter = attr(sp_quarters, 'names'),
CV = as.data.frame(do.call("rbind", sp_cv))$V1)
emerging_cv = lapply(emerging_quarters, calculate_cv)
emerging_cv = data.frame(
Quarter = attr(emerging_quarters, 'names'),
CV = as.data.frame(do.call("rbind", emerging_cv))$V1)
# Import stock data
sp_data = read.csv('SP.csv')
emerging_data = read.csv('EEM.csv')
# Split data into quarters of the year
library(lubricate)
sp_quarters = split(sp_data, quarter(sp_data$Date, with_year=TRUE))
emerging_quarters = split(emerging_data, quarter(emerging_data$Date, with_year=TRUE))
# Analyze the coefficient of variation
calculate_cv = function(vec) {
return (sd(vec$Adj.Close) / mean(vec$Adj.Close))
}
# Calculate cv for each quarter and combine into a single dataframe
sp_cv = lapply(sp_quarters, calculate_cv)
sp_cv = data.frame(
Quarter = attr(sp_quarters, 'names'),
CV = as.data.frame(do.call("rbind", sp_cv))$V1)
emerging_cv = lapply(emerging_quarters, calculate_cv)
emerging_cv = data.frame(
Quarter = attr(emerging_quarters, 'names'),
CV = as.data.frame(do.call("rbind", emerging_cv))$V1)
sp_data = read.csv('SP.csv')
emerging_data = read.csv('EEM.csv')
setwd("~/Documents/ECON/r_rpoject")
# Import stock data
sp_data = read.csv('SP.csv')
emerging_data = read.csv('EEM.csv')
# Split data into quarters of the year
library(lubricate)
sp_quarters = split(sp_data, quarter(sp_data$Date, with_year=TRUE))
emerging_quarters = split(emerging_data, quarter(emerging_data$Date, with_year=TRUE))
# Analyze the coefficient of variation
calculate_cv = function(vec) {
return (sd(vec$Adj.Close) / mean(vec$Adj.Close))
}
# Calculate cv for each quarter and combine into a single dataframe
sp_cv = lapply(sp_quarters, calculate_cv)
sp_cv = data.frame(
Quarter = attr(sp_quarters, 'names'),
CV = as.data.frame(do.call("rbind", sp_cv))$V1)
emerging_cv = lapply(emerging_quarters, calculate_cv)
emerging_cv = data.frame(
Quarter = attr(emerging_quarters, 'names'),
CV = as.data.frame(do.call("rbind", emerging_cv))$V1)
library(lubricate)
package(lubricate)
install.packages(lubricate)
install.packages('lubricate')
library(ggplot)
install.packages("lubridate", dependencies=TRUE, repos='http://cran.rstudio.com/')
install.packages("lubridate", dependencies=TRUE, repos='http://cran.rstudio.com/')
library(lubricate)
library('lubricate')
library(lubridate)
library(lubricate)
# Import stock data
sp_data = read.csv('SP.csv')
emerging_data = read.csv('EEM.csv')
# Split data into quarters of the year
install.packages("lubridate", dependencies=TRUE, repos='http://cran.rstudio.com/')
library(lubricate)
sp_quarters = split(sp_data, quarter(sp_data$Date, with_year=TRUE))
emerging_quarters = split(emerging_data, quarter(emerging_data$Date, with_year=TRUE))
# Analyze the coefficient of variation
calculate_cv = function(vec) {
return (sd(vec$Adj.Close) / mean(vec$Adj.Close))
}
# Calculate cv for each quarter and combine into a single dataframe
sp_cv = lapply(sp_quarters, calculate_cv)
sp_cv = data.frame(
Quarter = attr(sp_quarters, 'names'),
CV = as.data.frame(do.call("rbind", sp_cv))$V1)
emerging_cv = lapply(emerging_quarters, calculate_cv)
emerging_cv = data.frame(
Quarter = attr(emerging_quarters, 'names'),
CV = as.data.frame(do.call("rbind", emerging_cv))$V1)
